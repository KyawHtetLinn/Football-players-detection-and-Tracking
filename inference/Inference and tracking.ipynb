{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YJqVUs7vsCl2"},"outputs":[],"source":["!pip install kaggle --upgrade --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jE1CDAU0sa4W"},"outputs":[],"source":["import os\n","from getpass import getpass\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10581,"status":"ok","timestamp":1678905200790,"user":{"displayName":"Kyaw Htet","userId":"07355776497006824084"},"user_tz":-390},"id":"CAJuw2V6sc9c","outputId":"bbd967b9-3495-40ac-885f-d28ed98773df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter KAGGLE_USERNAME secret value: ··········\n","Enter KAGGLE_KEY secret value: ··········\n"]}],"source":["# os.environ['KAGGLE_USERNAME'] = getpass('Enter KAGGLE_USERNAME secret value: ')\n","# os.environ['KAGGLE_KEY'] = getpass('Enter KAGGLE_KEY secret value: ')"]},{"cell_type":"code","source":["os.environ['KAGGLE_USERNAME'] = 'kyawlin'\n","os.environ['KAGGLE_KEY'] = '24d3269babdaae2289340829b8434315'"],"metadata":{"id":"OVQ2Yp0-rYQq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RLF-EVxvDQZP"},"source":["## Download Kaggle Test Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12699,"status":"ok","timestamp":1678905217458,"user":{"displayName":"Kyaw Htet","userId":"07355776497006824084"},"user_tz":-390},"id":"hx-JX9mhqy_x","outputId":"34e173e4-7a67-4535-871d-aeb025127838"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading football-player-detection.zip to /content\n","100% 147M/147M [00:08<00:00, 22.2MB/s]\n","100% 147M/147M [00:08<00:00, 17.8MB/s]\n","Archive:  /content/football-player-detection.zip\n","  inflating: 20230212_last_model.pt  \n","  inflating: Faster-RCNN.txt         \n"]}],"source":["!kaggle datasets download -d kyawlin/football-player-detection\n","!unzip /content/football-player-detection.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uK-5mky0e4F-"},"outputs":[],"source":["# # Extract all frames from video\n","\n","# def extract_all(vid_pth,folder_name):\n","#   if not os.path.exists(folder_name):\n","#       os.makedirs(folder_name)\n","\n","#   vidcap = cv2.VideoCapture(vid_pth)\n","#   success,image = vidcap.read()\n","#   count = 0\n","#   while success:\n","#     cv2.imwrite(\"all_frames/frame_{}.jpg\".format(str(count).zfill(3)), image)     # save frame as JPEG file      \n","#     success,image = vidcap.read()\n","#     # print('Read a new frame: ', success)\n","#     count += 1\n","#   print('Done !')\n","#   print('No. of all frames : ',len(os.listdir('/content/all_frames')))\n","\n","# extract_all(vid_pth,'all_frames')    # extract all frames from videos"]},{"cell_type":"markdown","metadata":{"id":"dUAQWxSld3qq"},"source":["## Import Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3109,"status":"ok","timestamp":1678905220563,"user":{"displayName":"Kyaw Htet","userId":"07355776497006824084"},"user_tz":-390},"id":"jArvd65uwB9Y","outputId":"4a564b81-274e-4568-8a91-b2aceb4225ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["20230315\n"]}],"source":["#==================\n","# Import libraries\n","#==================\n","import gc\n","import cv2\n","import glob\n","import time\n","import copy\n","import random\n","\n","import numpy as np \n","import pandas as pd \n","import os\n","from PIL import Image\n","from glob import glob\n","import xml.etree.ElementTree as ET \n","\n","# from omegaconf import OmegaConf\n","from pathlib import Path \n","from typing import Union, Tuple, List, Iterable, Dict \n","from collections import defaultdict\n","\n","import logging \n","from logging import  getLogger, StreamHandler, Formatter\n","\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torch.utils.data import TensorDataset\n","from torch.optim import lr_scheduler \n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from base64 import b64encode\n","from IPython.display import HTML\n","\n","\n","plt.style.use(['default']) \n","\n","from datetime import datetime\n","today = str(datetime.today()).split(\" \")[0].replace(\"-\", \"\")\n","print(today)"]},{"cell_type":"markdown","metadata":{"id":"9PGdzcZbd8my"},"source":["## Configs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6MG7uBTIx-H2"},"outputs":[],"source":["#==================\n","# Config\n","#==================\n","class CFG:\n","    # path\n","    model = \"/content/20230212_last_model.pt\"\n","    bdd_xml = \"\"\n","    bdd_img = \"\"\n","    test_path = \"/content/frames\"\n","    log_path = './'\n","    # class of dataset\n","    dataset_class = ['ball','goalkeeper','player','referee']\n","    # colors (RGB)\n","    colors = ((0,0,0),(222,49,99),(100,149,237),(255,191,0),(136,78,160))\n","    # hyper prams of Faster-RCNN\n","    epochs = 10\n","    batch_size = 1\n","    lr = 0.005 \n","    wd = 1e-6\n","    scheduler = 'CosineAnnealingLR' # ReduceLROnPlateau\n","    min_lr = 1e-6\n","    T_max = 2400\n","    T_0 = 25\n","    scale = 1080 # 720 # image_scale (Vertical)\n","    # hyper prams of Faster-RCNN inference\n","    threshold = 0.6\n","    # seed\n","    seed = 2022\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n","\n","cfg = CFG()"]},{"cell_type":"markdown","metadata":{"id":"LEOS3AHXeB5h"},"source":["## Import Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":717,"status":"ok","timestamp":1678905799477,"user":{"displayName":"Kyaw Htet","userId":"07355776497006824084"},"user_tz":-390},"id":"hDSrDVq9yZDA","outputId":"2bf7ead6-6ea0-484e-a788-5a7c6d55adb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n"]}],"source":["#==================\n","# Seed\n","#==================\n","def set_seed(seed = 45):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    print('> SEEDING DONE')\n","    \n","set_seed(cfg.seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZ_JycCOydbN"},"outputs":[],"source":["#==================\n","# Logger\n","#==================\n","logger = getLogger(__name__)\n","logger.setLevel(logging.DEBUG)\n","filehandler = logging.FileHandler(os.path.join(cfg.log_path, \"Faster-RCNN.txt\"))\n","streamhander = StreamHandler()\n","filehandler.setLevel(logging.DEBUG)\n","streamhander.setLevel(logging.DEBUG)\n","handler_format = Formatter('[%(asctime)s][%(name)s][%(levelname)s][%(message)s]')\n","filehandler.setFormatter(handler_format)\n","streamhander.setFormatter(handler_format)\n","logger.addHandler(filehandler)\n","logger.addHandler(streamhander)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4661,"status":"ok","timestamp":1678905810718,"user":{"displayName":"Kyaw Htet","userId":"07355776497006824084"},"user_tz":-390},"id":"uiHV3vZ9yj_A","outputId":"4ba5fad5-aec7-4e37-cec8-fa622c0ea263"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# =====================\n","# Import Model\n","# =====================\n","data_class = cfg.dataset_class\n","data_class.insert(0, \"__background__\")\n","classes = tuple(data_class) \n","\n","model_inf = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n","    weights=None, progress=False,\n","    num_classes=91, weights_backbone=None, trainable_backbone_layers=None\n",")\n","num_classes = len(cfg.dataset_class)\n","in_features = model_inf.roi_heads.box_predictor.cls_score.in_features\n","model_inf.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","model_inf.load_state_dict(torch.load(cfg.model))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnqWDdEt0e-f"},"outputs":[],"source":["import glob\n","import pylab\n","from tqdm import tqdm\n","# img_list = sorted(glob.glob(cfg.test_path+'/*.jpg'))"]},{"cell_type":"markdown","metadata":{"id":"K5LOkzmKkZIB"},"source":["## Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5LgG5j30oRZ"},"outputs":[],"source":["def convert_frames2video(img_pth,vid_name):  # Detected frames into video\n","  img_array = []\n","  for filename in tqdm(sorted(glob.glob(img_pth+'/*.jpg'))):\n","      img = cv2.imread(filename)\n","      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","      height, width, layers = img.shape\n","      size = (width,height)\n","      img_array.append(img)\n","      # print(filename, ' - ', size)\n","\n","  out = cv2.VideoWriter(vid_name+'.avi',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n","  \n","  for i in range(len(img_array)):\n","      out.write(cv2.cvtColor(img_array[i], cv2.COLOR_RGB2BGR))\n","  out.release()\n","  print('Converting completed. '+vid_name+'.avi created ...')\n","\n","def convert_avi_to_mp4(avi_file_path, output_name):  # avi2mp4\n","    os.popen(\"ffmpeg -i '{input}' -ac 2 -b:v 2000k -c:a aac -c:v libx264 -b:a 160k -vprofile high -bf 0 -strict experimental -f mp4 '{output}.mp4'\".format(input = avi_file_path, output = output_name))\n","    return True\n","\n","\n","## Detect video and generate output frames ##\n","\n","def detect_video(output_,vid,device):\n","  if not os.path.exists(output_):\n","    os.mkdir(output_)\n","  model_inf.to(device)\n","  model_inf.eval()\n","  vidcap = cv2.VideoCapture(vid)\n","  success,image = vidcap.read()\n","  count = 0\n","  while success:\n","    # cv2.imwrite(\"all_frames/frame_{}.jpg\".format(str(count).zfill(3)), image)     # save frame as JPEG file      \n","    # print('Read a new frame: ', success)\n","    # img = cv2.imread(image)\n","    success,image = vidcap.read()\n","    try :\n","      img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    except:\n","      pass;\n","    image_tensor = torchvision.transforms.functional.to_tensor(img)\n","    with torch.no_grad():\n","        prediction = model_inf([image_tensor.to(device)])\n","    \n","    for i,box in enumerate(prediction[0]['boxes']):\n","        score = prediction[0]['scores'][i].cpu().numpy()\n","        if score > cfg.threshold:\n","            score = round(float(score),2)\n","            cat = prediction[0]['labels'][i].cpu().numpy()\n","            txt = '{} {}'.format(classes[int(cat)], str(score))\n","            font = cv2.FONT_HERSHEY_SIMPLEX\n","            cat_size = cv2.getTextSize(txt, font, 0.5, 2)[0]\n","            c = cfg.colors[int(cat)]\n","            box=box.cpu().numpy().astype('int')\n","            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), c , 2)\n","            cv2.rectangle(img,(box[0], box[1] - cat_size[1] - 2),(box[0] + cat_size[0], box[1] - 2), c, -1)\n","            cv2.putText(img, txt, (box[0], box[1] - 2), font, 0.5, (0, 0, 0), thickness=1, lineType=cv2.LINE_AA)\n","    cv2.imwrite(output_ + '/frame_'+str(count+1).zfill(3)+'.jpg',cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n","    print('frame '+ str(count)+' detected ...')\n","    count += 1 \n","  # plt.show()\n","  print(\"Completed !\")"]},{"cell_type":"markdown","metadata":{"id":"PlK4IiIJePba"},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBC45yjS_70M"},"outputs":[],"source":["vid_pth = '/content/019d5b34_1.mp4'   # video path\n","op_pth = '/content/results'           # output frames path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LyQww5NdENnb"},"outputs":[],"source":["detect_video(op_pth,vid_pth,device) # Inference on video"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37781,"status":"ok","timestamp":1676828252793,"user":{"displayName":"Kyaw Htet Linn","userId":"00027635402324129248"},"user_tz":-390},"id":"Pono9PCkBpaf","outputId":"5766938e-baaa-483e-cccd-60f04865f951"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 750/750 [00:24<00:00, 30.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Converting completed...\n"]}],"source":["convert_frames2video(op_pth,'detect_output') # convert detected frames into video\n","\n","convert_avi_to_mp4('detect_output.avi','detected') # avi to mp4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFmvbH-5Fncy"},"outputs":[],"source":["# Display the detected video\n","input_path = '/content/detect_output.avi' # Detected video path\n","compressed_path = \"/content/compressed_output.mp4\"  # Compressed video path\n","\n","os.system(f\"ffmpeg -i {input_path} -vcodec libx264 {compressed_path}\")\n","\n","# Show video\n","mp4 = open(compressed_path,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=800 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"]},{"cell_type":"markdown","metadata":{"id":"iGcAEhTigzp7"},"source":["## ByteTrack"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34436,"status":"ok","timestamp":1678906121594,"user":{"displayName":"Kyaw Htet","userId":"07355776497006824084"},"user_tz":-390},"id":"_VM49DPNg2rf","outputId":"f49ccf49-5fd2-4270-9ee3-2822801ea0c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'ByteTrack' already exists and is not an empty directory.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (1.22.4)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (1.13.1+cu116)\n","Requirement already satisfied: opencv_python in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (4.6.0.66)\n","Requirement already satisfied: loguru in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (0.6.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (0.19.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (4.65.0)\n","Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (0.14.1+cu116)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n","Collecting thop\n","  Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Collecting ninja\n","  Using cached ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (0.8.10)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (2.11.2)\n","Collecting lap\n","  Using cached lap-0.4.0-cp39-cp39-linux_x86_64.whl\n","Collecting motmetrics\n","  Using cached motmetrics-1.4.0-py3-none-any.whl (161 kB)\n","Collecting filterpy\n","  Using cached filterpy-1.4.5-py3-none-any.whl\n","Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (3.1.0)\n","Collecting onnx==1.8.1\n","  Using cached onnx-1.8.1.tar.gz (5.2 MB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting onnxruntime==1.8.0\n","  Using cached onnxruntime-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","Collecting onnx-simplifier==0.3.5\n","  Using cached onnx_simplifier-0.3.5-py3-none-any.whl\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnx==1.8.1->-r requirements.txt (line 20)) (3.19.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from onnx==1.8.1->-r requirements.txt (line 20)) (1.15.0)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx==1.8.1->-r requirements.txt (line 20)) (4.5.0)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime==1.8.0->-r requirements.txt (line 21)) (23.3.3)\n","Collecting onnxoptimizer>=0.2.5\n","  Using cached onnxoptimizer-0.3.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645 kB)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->-r requirements.txt (line 6)) (3.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2023.2.28)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.9.0)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->-r requirements.txt (line 6)) (23.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.10.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.10.0->-r requirements.txt (line 8)) (2.25.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 13)) (2.16.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.38.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.4.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 13)) (2.2.3)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.51.3)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.6.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 13)) (63.4.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard->-r requirements.txt (line 13)) (3.4.1)\n","Collecting xmltodict>=0.12.0\n","  Using cached xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from motmetrics->-r requirements.txt (line 15)) (1.4.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from filterpy->-r requirements.txt (line 16)) (3.5.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 13)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 13)) (6.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.23.1->motmetrics->-r requirements.txt (line 15)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.23.1->motmetrics->-r requirements.txt (line 15)) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 8)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 8)) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 8)) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.10.0->-r requirements.txt (line 8)) (4.0.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 13)) (2.1.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy->-r requirements.txt (line 16)) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy->-r requirements.txt (line 16)) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy->-r requirements.txt (line 16)) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy->-r requirements.txt (line 16)) (4.39.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 13)) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 13)) (3.2.2)\n","Building wheels for collected packages: onnx\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for onnx \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for onnx (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n","\u001b[31m  ERROR: Failed building wheel for onnx\u001b[0m\u001b[31m\n","\u001b[0mFailed to build onnx\n","\u001b[31mERROR: Could not build wheels for onnx, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0mrunning develop\n","/usr/local/lib/python3.9/dist-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n","  warnings.warn(\n","running egg_info\n","writing yolox.egg-info/PKG-INFO\n","writing dependency_links to yolox.egg-info/dependency_links.txt\n","writing top-level names to yolox.egg-info/top_level.txt\n","package init file 'datasets/__init__.py' not found (or not a regular file)\n","package init file 'build/__init__.py' not found (or not a regular file)\n","package init file 'assets/__init__.py' not found (or not a regular file)\n","package init file 'deploy/__init__.py' not found (or not a regular file)\n","package init file 'tools/__init__.py' not found (or not a regular file)\n","package init file 'exps/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/__init__.py' not found (or not a regular file)\n","package init file 'videos/__init__.py' not found (or not a regular file)\n","package init file 'datasets/data_path/__init__.py' not found (or not a regular file)\n","package init file 'deploy/TensorRT/__init__.py' not found (or not a regular file)\n","package init file 'deploy/DeepStream/__init__.py' not found (or not a regular file)\n","package init file 'deploy/ONNXRuntime/__init__.py' not found (or not a regular file)\n","package init file 'deploy/ncnn/__init__.py' not found (or not a regular file)\n","package init file 'deploy/TensorRT/cpp/__init__.py' not found (or not a regular file)\n","package init file 'deploy/TensorRT/python/__init__.py' not found (or not a regular file)\n","package init file 'deploy/TensorRT/cpp/include/__init__.py' not found (or not a regular file)\n","package init file 'deploy/TensorRT/cpp/src/__init__.py' not found (or not a regular file)\n","package init file 'deploy/DeepStream/includes/__init__.py' not found (or not a regular file)\n","package init file 'deploy/DeepStream/images/__init__.py' not found (or not a regular file)\n","package init file 'deploy/DeepStream/cmake/__init__.py' not found (or not a regular file)\n","package init file 'deploy/DeepStream/src/__init__.py' not found (or not a regular file)\n","package init file 'deploy/ncnn/cpp/__init__.py' not found (or not a regular file)\n","package init file 'deploy/ncnn/cpp/include/__init__.py' not found (or not a regular file)\n","package init file 'deploy/ncnn/cpp/src/__init__.py' not found (or not a regular file)\n","package init file 'exps/example/__init__.py' not found (or not a regular file)\n","package init file 'exps/default/__init__.py' not found (or not a regular file)\n","package init file 'exps/example/mot/__init__.py' not found (or not a regular file)\n","package init file 'yolox/tracker/__init__.py' not found (or not a regular file)\n","package init file 'yolox/motdt_tracker/__init__.py' not found (or not a regular file)\n","package init file 'yolox/tracking_utils/__init__.py' not found (or not a regular file)\n","package init file 'yolox/deepsort_tracker/__init__.py' not found (or not a regular file)\n","package init file 'yolox/sort_tracker/__init__.py' not found (or not a regular file)\n","package init file 'yolox/layers/csrc/__init__.py' not found (or not a regular file)\n","package init file 'yolox/layers/csrc/cocoeval/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/trades/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/motr/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/qdtrack/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/transtrack/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/fairmot/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/ctracker/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/centertrack/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/cstrack/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/jde/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/trades/mot_online/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/motr/mot_online/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/qdtrack/mot_online/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/transtrack/mot_online/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/ctracker/mot_online/__init__.py' not found (or not a regular file)\n","package init file 'tutorials/centertrack/mot_online/__init__.py' not found (or not a regular file)\n","/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","  warnings.warn(msg.format('we could not find ninja.'))\n","reading manifest file 'yolox.egg-info/SOURCES.txt'\n","adding license file 'LICENSE'\n","writing manifest file 'yolox.egg-info/SOURCES.txt'\n","running build_ext\n","copying build/lib.linux-x86_64-3.9/yolox/_C.cpython-39-x86_64-linux-gnu.so -> yolox\n","Creating /usr/local/lib/python3.9/dist-packages/yolox.egg-link (link to .)\n","yolox 0.1.0 is already the active version in easy-install.pth\n","\n","Installed /content/ByteTrack\n","Processing dependencies for yolox==0.1.0\n","Finished processing dependencies for yolox==0.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: cython_bbox in /usr/local/lib/python3.9/dist-packages (0.1.3)\n"]}],"source":["!git clone https://github.com/ifzhang/ByteTrack.git\n","!cd ByteTrack && pip3 install -r requirements.txt\n","!cd ByteTrack && python3 setup.py develop\n","!pip install cython_bbox"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-aZofM2jABC"},"outputs":[],"source":["import sys\n","sys.path.append(\"/content/ByteTrack\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgQMzd0sjHQz"},"outputs":[],"source":["!pip install onemetric --quiet\n","!pip install loguru --quiet\n","!pip install thop --quiet\n","!pip install lap --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uApqpiq1jKr8"},"outputs":[],"source":["from dataclasses import dataclass\n","\n","@dataclass(frozen=True)\n","class BYTETrackerArgs:\n","    track_thresh: float = 0.25\n","    track_buffer: int = 30\n","    match_thresh: float = 0.8\n","    aspect_ratio_thresh: float = 3.0\n","    min_box_area: float = 1.0\n","    mot20: bool = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcY1guHLjQti"},"outputs":[],"source":["from yolox.tracker.byte_tracker import BYTETracker, STrack\n","from onemetric.cv.utils.iou import box_iou_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"neCItQPsKHEg"},"outputs":[],"source":["from typing import List\n","\n","import numpy as np\n","\n","\"\"\"\n","BYTETracker does not assign tracker_id to existing bounding boxes but rather\n","predicts the next bounding box position based on previous one. Therefore, we \n","need to find a way to match our bounding boxes with predictions.\n","\n","usage example:\n","\n","byte_tracker = BYTETracker(BYTETrackerArgs())\n","for frame in frames:\n","    ...\n","    results = model(frame, size=1280)\n","    detections = Detection.from_results(\n","        pred=results.pred[0].cpu().numpy(), \n","        names=model.names)\n","    ...\n","    tracks = byte_tracker.update(\n","        output_results=detections2boxes(detections=detections),\n","        img_info=frame.shape,\n","        img_size=frame.shape)\n","    detections = match_detections_with_tracks(detections=detections, tracks=tracks)\n","\"\"\"\n","\n","# converts List[Detection] into format that can be consumed by match_detections_with_tracks function\n","\n","# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n","def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n","    return np.array([\n","        track.tlbr\n","        for track\n","        in tracks\n","    ], dtype=float)\n","\n","\n","# matches our bounding boxes with predictions\n","def match_detections_with_tracks(prediction, tracks):\n","    detection_boxes = extract_boxes(prediction,with_score=False)\n","    tracks_boxes = tracks2boxes(tracks=tracks)\n","    iou = box_iou_batch(tracks_boxes, detection_boxes)\n","    track2detection = np.argmax(iou, axis=1)\n","    \n","    for tracker_index, detection_index in enumerate(track2detection):\n","        if iou[tracker_index, detection_index] != 0:\n","            prediction[0]['tracker_id'][detection_index] = tracks[tracker_index].track_id\n","            # print(tracker_index, ' - ',detection_index)\n","    return prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLTIrgfp-iZ_"},"outputs":[],"source":["# def extract_players_boxes(prediction,with_score=True):\n","#   boxes = prediction[0]['boxes'].cpu().detach().numpy()\n","#   scores = prediction[0]['scores'].cpu().detach().numpy()\n","#   labels = prediction[0]['labels'].cpu().detach().numpy()\n","\n","#   # Extract only players detections\n","#   boxes = boxes[np.where(labels == 3)]       \n","#   scores = scores[np.where(labels == 3)]\n","\n","#   players_detections = list()\n","#   for b,s in zip(boxes,scores):\n","#     if with_score == False :\n","#       players_detections.append(([b[0],b[1],b[2],b[3]]))\n","#     else :\n","#       players_detections.append(([b[0],b[1],b[2],b[3],s]))\n","#   return np.array(players_detections)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twSlZXrs_UA2"},"outputs":[],"source":["def extract_boxes(prediction,with_score=True):\n","  boxes = prediction[0]['boxes'].cpu().detach().numpy()\n","  scores = prediction[0]['scores'].cpu().detach().numpy()\n","  labels = prediction[0]['labels'].cpu().detach().numpy()\n","\n","  # Extract only players detections\n","  # boxes = boxes[np.where(labels == 3)]       \n","  # scores = scores[np.where(labels == 3)]\n","  detections = list()\n","  for b,s in zip(boxes,scores):\n","    if with_score == False :\n","      detections.append(([b[0],b[1],b[2],b[3]]))\n","    else :\n","      detections.append(([b[0],b[1],b[2],b[3],s]))\n","  return np.array(detections)"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":806,"status":"ok","timestamp":1678907432426,"user":{"displayName":"Kyaw Htet","userId":"07355776497006824084"},"user_tz":-390},"id":"RRASVLymm2sM"},"outputs":[],"source":["# !rm -r /content/test\n","if not os.path.exists('test'):  # for detected frames\n","  os.mkdir('test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KIZt2gTRihA8"},"outputs":[],"source":["model_inf.to(device)\n","model_inf.eval()\n","vidcap = cv2.VideoCapture('/content/Project Name.mp4')\n","success,image = vidcap.read()\n","count = 0\n","# initiate tracker\n","byte_tracker = BYTETracker(BYTETrackerArgs())\n","\n","while success:\n","  # cv2.imwrite(\"all_frames/frame_{}.jpg\".format(str(count).zfill(3)), image)     # save frame as JPEG file      \n","  # print('Read a new frame: ', success)\n","  # img = cv2.imread(image)\n","  success,image = vidcap.read()\n","  try :\n","    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","  except:\n","    pass;\n","  image_tensor = torchvision.transforms.functional.to_tensor(img)\n","  with torch.no_grad():\n","      predictions = model_inf([image_tensor.to(device)])\n","      t = list()\n","      for b in predictions[0]['boxes']:\n","        t.append(None)\n","      predictions[0]['tracker_id'] = t\n","\n","  tracks = byte_tracker.update(\n","    output_results=extract_boxes(predictions),\n","    img_info=img.shape,\n","    img_size=img.shape)\n","  tracked_detections = match_detections_with_tracks(prediction = predictions, tracks=tracks)\n","  # print(predictions)\n","  for i,box in enumerate(tracked_detections[0]['boxes']):\n","    score = tracked_detections[0]['scores'][i].cpu().numpy()\n","    if tracked_detections[0]['tracker_id'][i] == None : continue\n","    else : \n","      if score > cfg.threshold:\n","        score = round(float(score),2)\n","        cat = tracked_detections[0]['labels'][i].cpu().numpy()\n","        txt = '{} {}'.format(classes[int(cat)], str(score))\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        cat_size = cv2.getTextSize(txt, font, 0.5, 2)[0]\n","        c = cfg.colors[int(cat)]\n","        box=box.cpu().numpy().astype('int')\n","        cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), c , 2)\n","        cv2.rectangle(img,(box[0], box[1] - cat_size[1] - 2),(box[0] + cat_size[0], box[1] - 2), c, -1)\n","        cv2.putText(img, txt, (box[0], box[1] - 2), font, 0.5, (0, 0, 0), thickness=1, lineType=cv2.LINE_AA)\n","    # # plt.imshow(img)\n","  img_name = '/content/test' + '/test_'+str(count+1).zfill(4)+'.jpg'\n","  cv2.imwrite(img_name,cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n","  count += 1 \n","  print('frame '+ str(count)+' detected ...')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tLVqXyhZnWFE"},"outputs":[],"source":["convert_frames2video('/content/test','tracked_output') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tD6wIj1j1UP3"},"outputs":[],"source":["input_path = '/content/tracked_output.avi' # Detected video path\n","compressed_path = \"/content/c.mp4\"  # Compressed video path"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1UtrMz_YdUr0AnoP8A_-koFD9PzDYOK1_"},"executionInfo":{"elapsed":164577,"status":"ok","timestamp":1678907047116,"user":{"displayName":"Kyaw Htet","userId":"07355776497006824084"},"user_tz":-390},"id":"DWqs9m9MHg09","outputId":"eee21986-1daf-470f-a460-e00984184b56"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Display the tracked detected video\n","\n","os.system(f\"ffmpeg -i {input_path} -vcodec libx264 {compressed_path}\")\n","\n","# Show video\n","mp4 = open(compressed_path,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=800 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1VtJH-joKUB"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}